This work contributes to the broader AI community by advancing principled mechanisms for controllable and reliable model modification. By improving the precision of unlearning in text-to-image diffusion models, it supports AI assurance through verifiable post-deployment updates without degrading core capabilities. More broadly, such methods enable responsible adaptation of deployed models in response to societal, legal, and policy requirements. In this context, surgical unlearning provides a practical pathway for copyright compliance and stakeholder-driven interventions, while maintaining the usefulness of large-scale generative systems.